{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer as WNL\n",
    "import scipy\n",
    "from IPython.display import clear_output as clr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'LDA',\n",
       " 'stackoverflow-data-idf.json',\n",
       " 'stackoverflow-test.json',\n",
       " 'TF-IDF',\n",
       " 'train_corpus',\n",
       " 'Unigram']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining data directory\n",
    "data_dir = os.getcwd() + '/../'\n",
    "# Check in contents of current dir are same as expected\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir + 'train_corpus')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    serialize private struct can it be do i have p...\n",
       "1    how do i prevent float right content from over...\n",
       "2    gradle command line i m try to run shell scrip...\n",
       "3    loop variable as parameter in asynchronous fun...\n",
       "4    canot get href value hi i need to valid href b...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vocab:\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        Corpus : list of docs\n",
    "        \"\"\"\n",
    "        self.dictionary = {}\n",
    "        self.vocab_size = 0\n",
    "        self.make_vocab(corpus)\n",
    "        self.inv_dictionary = {v: k for k, v in self.dictionary.items()}\n",
    "    \n",
    "    def make_vocab(self,corpus):\n",
    "        \n",
    "        count = 0\n",
    "        for doc in corpus:\n",
    "            for word in doc.strip().split():\n",
    "                if(word in self.dictionary.keys()):\n",
    "                    pass\n",
    "                else:\n",
    "                    self.dictionary[word] = count\n",
    "                    count += 1\n",
    "        \n",
    "        self.vocab_size = count\n",
    "        assert(len(self.dictionary.keys()) == count), \"Wrong Number of words added\"\n",
    "        \n",
    "    def get_index(self,word):\n",
    "        if(word in self.dictionary.keys()):\n",
    "            return self.dictionary[word]\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def get_word(self,index):\n",
    "        if(index in self.inv_dictionary.keys()):\n",
    "            return self.inv_dictionary[index]\n",
    "        else:\n",
    "            return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict = vocab(list(data.iloc[0:500].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    \n",
    "    def __init__(self,vocab, K):\n",
    "        \"\"\"\n",
    "        vocab : a dictionary containing all the words and corresponding indices\n",
    "        k : smoothing parameter for beta matrix\n",
    "        \"\"\"\n",
    "        self.vocab = vocab\n",
    "        self.V = vocab.vocab_size\n",
    "        self.K = K\n",
    "        self.alpha = np.zeros((self.K, 1)) + np.random.rand()\n",
    "        self.beta = np.random.rand(self.K, self.V)\n",
    "        self.gamma = np.random.rand(self.K , 1)\n",
    "        self.digamma = scipy.special.digamma\n",
    "        self.eps = 10e-8\n",
    "        \n",
    "        \n",
    "    def train(self, corpus, epochs = 1):\n",
    "        \n",
    "        M = len(corpus)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            beta = np.zeros((self.K, self.V))\n",
    "            grad_alpha = 0\n",
    "            hesn_alpha = 0\n",
    "            print(\"Initialized\")\n",
    "            count = 0\n",
    "            for doc in corpus:\n",
    "                clr(wait = True)\n",
    "                count += 1\n",
    "                print(\"epoch : \", epoch, \" doc init: \", count)\n",
    "                words = doc.strip().split(\" \")\n",
    "                N = len(words)\n",
    "                phi = np.zeros((N, self.K))\n",
    "                gamma = np.zeros((self.K, 1))\n",
    "\n",
    "\n",
    "                for j, word in enumerate(words):\n",
    "\n",
    "                    index = self.vocab.get_index(word)\n",
    "                    beta_v = np.log(self.beta[:,index].reshape(self.K, 1))\n",
    "                    phi_n = self.calc_phi(beta_v)\n",
    "                    phi[j, :] = phi_n.reshape(-1)\n",
    "                    \n",
    "                \n",
    "                print(\"epoch : \", epoch, \"made phi\", count)\n",
    "\n",
    "                for i in range(self.K):\n",
    "                    gamma[i] = self.alpha[i] + np.sum(phi[:, i])\n",
    "\n",
    "\n",
    "                print(\"epoch : \", epoch, \"made gamma\", count)\n",
    "                \n",
    "\n",
    "                for i in range(self.K):\n",
    "                    for j in range(self.V):\n",
    "                        val = 0\n",
    "                        for k, word in enumerate(words):\n",
    "                            index = self.vocab.get_index(word)\n",
    "                            if(j == index):\n",
    "                                val += phi[k, i]\n",
    "\n",
    "                        beta[i,j] = val\n",
    "                        \n",
    "                print(\"epoch : \", epoch, \"made beta\", count)\n",
    "\n",
    "                beta = beta/(np.sum(beta,  axis = 1).reshape(-1,1) + self.eps)\n",
    "\n",
    "                grad_alpha += self.digamma(np.sum(self.alpha)) - self.digamma(self.alpha)\n",
    "                grad_alpha += self.digamma(gamma) - self.digamma(np.sum(gamma))\n",
    "\n",
    "            # update params\n",
    "            self.beta = beta\n",
    "            self.gamma = gamma\n",
    "            self.alpha = self.alpha + 0.0001*grad_alpha.reshape(-1,1)\n",
    "            \n",
    "\n",
    "    def calc_phi(self, beta_v):\n",
    "        phi = np.exp(self.digamma(self.gamma) - self.digamma(np.sum(self.gamma))).reshape(self.K,1)\n",
    "        phi = beta_v*phi\n",
    "        phi = phi/(np.sum(phi, axis = 0) + self.eps)\n",
    "        return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LDA(myDict , 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  doc init:  15\n",
      "epoch :  0 made phi 15\n",
      "epoch :  0 made gamma 15\n"
     ]
    }
   ],
   "source": [
    "model.train(list(data.iloc[0:200].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001453065963037513"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
